{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't consider decision trump and simple decision tree due to lower results than other models by metric kaggle(accuracy): accordingly ~59% Ð¸ ~70% unlike ~76%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from functions_for_titanik import make_prediction_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to data\n",
    "\n",
    "PATH_TO_X_SAMPLE = \"X_sample.csv\"\n",
    "PATH_TO_Y_SAMPLE = \"y_sample.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data\n",
    "\n",
    "X_sample = pd.read_csv(PATH_TO_X_SAMPLE, index_col=\"PassengerId\")\n",
    "y_sample = pd.read_csv(PATH_TO_Y_SAMPLE, index_col=\"PassengerId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 891 entries, 1 to 891\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Pclass       891 non-null    int64  \n",
      " 1   Age          891 non-null    float64\n",
      " 2   SibSp        891 non-null    int64  \n",
      " 3   Parch        891 non-null    int64  \n",
      " 4   Fare         891 non-null    float64\n",
      " 5   Family_size  891 non-null    int64  \n",
      " 6   Sex_male     891 non-null    bool   \n",
      " 7   Embarked_Q   891 non-null    bool   \n",
      " 8   Embarked_S   891 non-null    bool   \n",
      "dtypes: bool(3), float64(2), int64(4)\n",
      "memory usage: 51.3 KB\n"
     ]
    }
   ],
   "source": [
    "X_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Disconnection\n",
    "\n",
    "k_disconnection = (7 * 891) // 10\n",
    "X_train, X_test = X_sample.iloc[:k_disconnection], X_sample.iloc[k_disconnection:]\n",
    "y_train, y_test = y_sample.iloc[:k_disconnection], y_sample.iloc[k_disconnection:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 623 entries, 1 to 623\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Pclass       623 non-null    int64  \n",
      " 1   Age          623 non-null    float64\n",
      " 2   SibSp        623 non-null    int64  \n",
      " 3   Parch        623 non-null    int64  \n",
      " 4   Fare         623 non-null    float64\n",
      " 5   Family_size  623 non-null    int64  \n",
      " 6   Sex_male     623 non-null    bool   \n",
      " 7   Embarked_Q   623 non-null    bool   \n",
      " 8   Embarked_S   623 non-null    bool   \n",
      "dtypes: bool(3), float64(2), int64(4)\n",
      "memory usage: 35.9 KB\n",
      " \n",
      "X_test:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 268 entries, 624 to 891\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Pclass       268 non-null    int64  \n",
      " 1   Age          268 non-null    float64\n",
      " 2   SibSp        268 non-null    int64  \n",
      " 3   Parch        268 non-null    int64  \n",
      " 4   Fare         268 non-null    float64\n",
      " 5   Family_size  268 non-null    int64  \n",
      " 6   Sex_male     268 non-null    bool   \n",
      " 7   Embarked_Q   268 non-null    bool   \n",
      " 8   Embarked_S   268 non-null    bool   \n",
      "dtypes: bool(3), float64(2), int64(4)\n",
      "memory usage: 15.4 KB\n"
     ]
    }
   ],
   "source": [
    "#Checking the data status #1\n",
    "print(\"X_train:\")\n",
    "X_train.info()\n",
    "print(\" \\nX_test:\")\n",
    "X_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "parameters = {\"criterion\": [\"entropy\", \"gini\"],\n",
    "              \"max_depth\": range(1, 10), \n",
    "              \"min_samples_split\": range(2, 10),\n",
    "              \"min_samples_leaf\": range(1, 10)\n",
    "              }\n",
    "\n",
    "grid_cv = GridSearchCV(clf, parameters, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the metrics show quite good results, but the hyperparameters are unstable, let's try to fix it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: DecisionTreeClassifier(max_depth=7, min_samples_leaf=4, min_samples_split=4)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Died       0.81      0.91      0.86       172\n",
      "    Survived       0.80      0.62      0.70        96\n",
      "\n",
      "    accuracy                           0.81       268\n",
      "   macro avg       0.81      0.77      0.78       268\n",
      "weighted avg       0.81      0.81      0.80       268\n",
      "\n",
      "CPU times: total: 21.2 s\n",
      "Wall time: 22.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "grid_cv.fit(X_train, y_train)\n",
    "best_model_grid = grid_cv.best_estimator_\n",
    "print(\"Best params:\", best_model_grid)\n",
    "print(classification_report(y_test, best_model_grid.predict(X_test), target_names=[\"Died\", \"Survived\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_grid_cv = RandomizedSearchCV(clf, parameters, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that each precision and recall has a spread of +-6, we would like precision and recall to be constant and at the same time the highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Died       0.80      0.95      0.87       172\n",
      "    Survived       0.87      0.56      0.68        96\n",
      "\n",
      "    accuracy                           0.81       268\n",
      "   macro avg       0.83      0.76      0.78       268\n",
      "weighted avg       0.82      0.81      0.80       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Simple RandomizedSearchCV\n",
    "\n",
    "rand_grid_cv.fit(X_train, y_train)\n",
    "print(classification_report(y_test, rand_grid_cv.predict(X_test), target_names=[\"Died\", \"Survived\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeating the code block several times, we will see that the most frequent  totals are: \"gini\", 7, 4, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gini 7 4 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Died       0.81      0.91      0.86       172\n",
      "    Survived       0.80      0.62      0.70        96\n",
      "\n",
      "    accuracy                           0.81       268\n",
      "   macro avg       0.81      0.77      0.78       268\n",
      "weighted avg       0.81      0.81      0.80       268\n",
      "\n",
      "CPU times: total: 2min 38s\n",
      "Wall time: 2min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Create start value our parameters\n",
    "md_lst = []\n",
    "msl_lst = []\n",
    "mss_lst = []\n",
    "\n",
    "entropy_count, gini_count = 0, 0\n",
    "md_value = -1\n",
    "msl_value = -1\n",
    "mss_value = -1\n",
    "\n",
    "#Going through 1000 RandomizedSearchCV and save parametrs\n",
    "for model in range(1000):\n",
    "    rand_grid_cv.fit(X_train, y_train)\n",
    "    local_best = rand_grid_cv.best_estimator_\n",
    "\n",
    "    if local_best.criterion == \"entropy\":\n",
    "        entropy_count += 1\n",
    "    else:\n",
    "        gini_count += 1\n",
    "    \n",
    "    md_lst.append(local_best.max_depth)\n",
    "    msl_lst.append(local_best.min_samples_leaf)\n",
    "    mss_lst.append(local_best.min_samples_split)\n",
    "\n",
    "#We choose the categorical value according to the fashion, and the numerical values according to the median\n",
    "if entropy_count > gini_count:\n",
    "    criterion_value = \"entropy\"\n",
    "elif entropy_count == gini_count:\n",
    "    criterion_value = \"gini\"\n",
    "    print(\"!\")\n",
    "else:\n",
    "    criterion_value = \"gini\"\n",
    "\n",
    "lst_start_values = [md_lst, msl_lst, mss_lst]\n",
    "lst_end_values = []\n",
    "for value in lst_start_values:\n",
    "    value = sorted(value)\n",
    "    lst_end_values.append((value[499] + value[500]) // 2)\n",
    "\n",
    "#Interpreting the result\n",
    "best_model_rand = DecisionTreeClassifier(criterion=criterion_value, max_depth=lst_end_values[0], min_samples_leaf=lst_end_values[1], min_samples_split=lst_end_values[2])\n",
    "best_model_rand.fit(X_train, y_train)\n",
    "print(best_model_rand.criterion, best_model_rand.max_depth, best_model_rand.min_samples_leaf, best_model_rand.min_samples_split)\n",
    "print(classification_report(y_test, best_model_rand.predict(X_test), target_names=[\"Died\", \"Survived\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are quite satisfied with these hyperparameters, but we will try to improve their result using these as a basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Died       0.81      0.91      0.86       172\n",
      "    Survived       0.80      0.62      0.70        96\n",
      "\n",
      "    accuracy                           0.81       268\n",
      "   macro avg       0.81      0.77      0.78       268\n",
      "weighted avg       0.81      0.81      0.80       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Use hyperparametrs from code block higher\n",
    "repitmodel_best_rand = DecisionTreeClassifier(criterion=\"gini\", max_depth=7, min_samples_leaf=4, min_samples_split=6)\n",
    "repitmodel_best_rand.fit(X_train, y_train)\n",
    "print(classification_report(y_test, repitmodel_best_rand.predict(X_test), target_names=[\"Died\", \"Survived\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This decision tree has all increased metric values, and for Survived precision they are higher by 0.04, for Died recall they are higher by 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Died       0.82      0.94      0.88       172\n",
      "    Survived       0.86      0.64      0.73        96\n",
      "\n",
      "    accuracy                           0.83       268\n",
      "   macro avg       0.84      0.79      0.80       268\n",
      "weighted avg       0.84      0.83      0.83       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "without_cv_1 = DecisionTreeClassifier(criterion=\"gini\", max_depth=3)\n",
    "without_cv_1.fit(X_train, y_train)\n",
    "whc_pred_1 = without_cv_1.predict(X_test)\n",
    "print(classification_report(y_test, whc_pred_1, target_names=[\"Died\", \"Survived\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This decision tree has almost all the increased metric values, and for Survived recall they are 0.06 higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Died       0.84      0.92      0.88       172\n",
      "    Survived       0.82      0.68      0.74        96\n",
      "\n",
      "    accuracy                           0.83       268\n",
      "   macro avg       0.83      0.80      0.81       268\n",
      "weighted avg       0.83      0.83      0.83       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "without_cv_2 = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5, min_samples_leaf=4)\n",
    "without_cv_2.fit(X_train, y_train)\n",
    "whc_pred_2 = without_cv_2.predict(X_test)\n",
    "print(classification_report(y_test, whc_pred_2, target_names=[\"Died\", \"Survived\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This decision tree has has a significant decrease for Dead recall by 0.09 and Survived precision by 0.07, but has a significant increase for Survived recall by 0.09 and for Dead precision by 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Died       0.84      0.84      0.84       172\n",
      "    Survived       0.71      0.71      0.71        96\n",
      "\n",
      "    accuracy                           0.79       268\n",
      "   macro avg       0.77      0.77      0.77       268\n",
      "weighted avg       0.79      0.79      0.79       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "without_cv_3 = DecisionTreeClassifier(max_depth=2)\n",
    "without_cv_3.fit(X_train, y_train)\n",
    "whc_pred_3 = without_cv_3.predict(X_test)\n",
    "print(classification_report(y_test, whc_pred_3, target_names=[\"Died\", \"Survived\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tree is similar to the previous one according to the results of metrics, only some metric values are higher or equal, only Survived recall can be lower or equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Died       0.84      0.85      0.85       172\n",
      "    Survived       0.73      0.71      0.72        96\n",
      "\n",
      "    accuracy                           0.80       268\n",
      "   macro avg       0.79      0.78      0.78       268\n",
      "weighted avg       0.80      0.80      0.80       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "without_cv_4 = DecisionTreeClassifier(criterion=\"gini\", min_samples_split=10)\n",
    "without_cv_4.fit(X_train, y_train)\n",
    "whc_pred_4 = without_cv_4.predict(X_test)\n",
    "print(classification_report(y_test,whc_pred_4, target_names=[\"Died\", \"Survived\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction for kaggle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_TEST = \"X_test_kaggle.csv\"\n",
    "X_test_kaggle = pd.read_csv(PATH_TO_TEST, index_col=\"PassengerId\")   # Test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make prediction files\n",
    "\n",
    "all_models = [without_cv_1, without_cv_2, without_cv_3, without_cv_4]\n",
    "\n",
    "for model_id in range(len(all_models)):\n",
    "    model_pred = all_models[model_id].predict(X_test_kaggle)\n",
    "    make_prediction_file(model_pred, X_test_kaggle, f\"whc_pred_{model_id + 1}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
